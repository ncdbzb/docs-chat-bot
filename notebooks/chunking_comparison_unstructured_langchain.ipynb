{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25d292",
   "metadata": {
    "vscode": {
     "languageId": "pip-requirements"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --quiet unstructured langchain langchain_openai langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортирование библиотек\n",
    "import io\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from unstructured.partition.api import partition_via_api\n",
    "from unstructured.documents.elements import Element\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для загрузки файла\n",
    "def load_file(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f770d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для парсинга с использованием unstructured\n",
    "def parse_with_unstructured(file_bytes, metadata_filename=\"document.docx\"):\n",
    "    file_obj = io.BytesIO(file_bytes)\n",
    "    elements = partition_via_api(\n",
    "        file=file_obj,\n",
    "        api_url=\"http://localhost:8111/general/v0/general\",\n",
    "        metadata_filename=metadata_filename,\n",
    "        strategy=\"auto\",\n",
    "        chunking_strategy=\"by_title\",\n",
    "        max_characters=1500,\n",
    "        new_after_n_chars=1200,\n",
    "        combine_under_n_chars=200,\n",
    "    )\n",
    "    return elements\n",
    "\n",
    "# Функция для парсинга с использованием langchain\n",
    "def parse_with_langchain(file_bytes):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    splitter = SemanticChunker(embeddings)\n",
    "    text = file_bytes.decode(\"utf-8\")\n",
    "    chunks = splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "# Загрузка файла\n",
    "file_path = \"path_to_your_file.docx\"  # Укажите путь к вашему файлу\n",
    "file_bytes = load_file(file_path)\n",
    "\n",
    "# Парсинг с использованием unstructured\n",
    "unstructured_elements = parse_with_unstructured(file_bytes)\n",
    "\n",
    "# Парсинг с использованием langchain\n",
    "langchain_chunks = parse_with_langchain(file_bytes)\n",
    "\n",
    "# Отображение результатов\n",
    "def display_chunks(elements, method_name):\n",
    "    display(HTML(f\"<h3>Результаты метода: {method_name}</h3>\"))\n",
    "    for i, el in enumerate(elements):\n",
    "        text = el.text.strip() if hasattr(el, 'text') else el\n",
    "        display(HTML(f\"<b>Чанк {i + 1}:</b><br>{text[:500]}...<br><br>\"))\n",
    "\n",
    "# Отображение результатов обоих методов\n",
    "display_chunks(unstructured_elements, \"Unstructured\")\n",
    "display_chunks(langchain_chunks, \"Langchain Semantic Chunking\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
