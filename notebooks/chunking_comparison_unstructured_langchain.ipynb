{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25d292",
   "metadata": {
    "vscode": {
     "languageId": "pip-requirements"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --quiet unstructured langchain langchain_experimental openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f770d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортирование библиотек\n",
    "import io\n",
    "import os\n",
    "from langchain.embeddings import Embeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from unstructured.partition.api import partition_via_api\n",
    "from unstructured.documents.elements import Element\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "class CustomOllamaEmbeddings(Embeddings):\n",
    "    def __init__(self):\n",
    "        self.model_name = \"bge-m3\"\n",
    "        self.client = OpenAI(\n",
    "            base_url=\"http://10.41.56.9:12121/v1\",  # ваш локальный OpenAI API\n",
    "            api_key=os.environ.get(\"LLM_API_KEY\", \"\"),  # ключ если нужен\n",
    "        )\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return self._get_embeddings(texts)\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self._get_embeddings([text])[0]\n",
    "\n",
    "    def _get_embeddings(self, input_texts):\n",
    "        response = self.client.embeddings.create(\n",
    "            model=self.model_name,\n",
    "            input=input_texts\n",
    "        )\n",
    "        return [e.embedding for e in response.data]\n",
    "\n",
    "# Функция для загрузки файла\n",
    "def load_file(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "# Функция для парсинга с использованием unstructured\n",
    "def parse_with_unstructured(file_bytes, metadata_filename=\"document.docx\"):\n",
    "    file_obj = io.BytesIO(file_bytes)\n",
    "    elements = partition_via_api(\n",
    "        file=file_obj,\n",
    "        api_url=\"http://localhost:8111/general/v0/general\",\n",
    "        metadata_filename=metadata_filename,\n",
    "        strategy=\"auto\",\n",
    "        chunking_strategy=\"by_title\",\n",
    "        max_characters=1500,\n",
    "        new_after_n_chars=1200,\n",
    "        combine_under_n_chars=200,\n",
    "    )\n",
    "    return elements\n",
    "\n",
    "# Функция для парсинга с использованием langchain\n",
    "def parse_with_langchain(file_bytes):\n",
    "    embeddings = CustomOllamaEmbeddings()\n",
    "    splitter = SemanticChunker(embeddings)\n",
    "    text = file_bytes.decode(\"utf-8\")\n",
    "    chunks = splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "# Загрузка файла\n",
    "file_path = \"path_to_your_file.docx\"  # Укажите путь к вашему файлу\n",
    "file_bytes = load_file(file_path)\n",
    "\n",
    "# Парсинг с использованием unstructured\n",
    "unstructured_elements = parse_with_unstructured(file_bytes)\n",
    "\n",
    "# Парсинг с использованием langchain\n",
    "langchain_chunks = parse_with_langchain(file_bytes)\n",
    "\n",
    "# Отображение результатов\n",
    "def display_chunks(elements, method_name):\n",
    "    display(HTML(f\"<h3>Результаты метода: {method_name}</h3>\"))\n",
    "    for i, el in enumerate(elements):\n",
    "        text = el.text.strip() if hasattr(el, 'text') else el\n",
    "        display(HTML(f\"<b>Чанк {i + 1}:</b><br>{text[:500]}...<br><br>\"))\n",
    "\n",
    "# Отображение результатов обоих методов\n",
    "display_chunks(unstructured_elements, \"Unstructured\")\n",
    "display_chunks(langchain_chunks, \"Langchain Semantic Chunking\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
